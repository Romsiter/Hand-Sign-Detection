This Project is based on Convolution Neural Network which is trained on about 18,000 custom images to do categorical classification of 26 classes, taken by us as input to use the model.
The project is used to detect the hand sign language of the deaf and dumb people by converting the hand signs into the corresponding equivalent letters 
according to ASL.
Due to time constraint we are unable to integrate our python code for hand sign detection into app, BUt we had our app layout ready which we designed using Figma.
The ipynb file contains the code which we used to train our model and evaluating it on some Test Data set.
We have also uploaded the ASL chart for the reference.
