{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_values([False, False, False, 'msvcp140.dll,msvcp140_1.dll'])\n"
     ]
    }
   ],
   "source": [
    "sys_details = tf.sysconfig.get_build_info()\n",
    "cuda_version = sys_details.values()\n",
    "print(cuda_version)\n",
    "#print(cuda_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FIleuCAjoFD8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0koUcJMJpEBD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16557 images belonging to 25 classes.\n",
      "Found 2500 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\Aditya Babaso Patil\\Desktop\\Data69',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\Aditya Babaso Patil\\Desktop\\Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=8, kernel_size=5,strides=1, activation='relu', input_shape=[224, 224, 3]))\n",
    "#cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=16, kernel_size=7,strides=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=5,strides=1, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=1, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=625, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=125, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=25, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XUj1W4PJptta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "518/518 [==============================] - 336s 642ms/step - loss: 0.7877 - accuracy: 0.7597 - val_loss: 0.0988 - val_accuracy: 0.9660\n",
      "Epoch 2/15\n",
      "518/518 [==============================] - 344s 663ms/step - loss: 0.1055 - accuracy: 0.9672 - val_loss: 0.0965 - val_accuracy: 0.9636\n",
      "Epoch 3/15\n",
      "518/518 [==============================] - 343s 661ms/step - loss: 0.0720 - accuracy: 0.9769 - val_loss: 0.0243 - val_accuracy: 0.9920\n",
      "Epoch 4/15\n",
      "518/518 [==============================] - 347s 669ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.0214 - val_accuracy: 0.9944\n",
      "Epoch 5/15\n",
      "518/518 [==============================] - 344s 663ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.0172 - val_accuracy: 0.9960\n",
      "Epoch 6/15\n",
      "518/518 [==============================] - 340s 656ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.0114 - val_accuracy: 0.9976\n",
      "Epoch 7/15\n",
      "518/518 [==============================] - 322s 622ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
      "Epoch 8/15\n",
      "518/518 [==============================] - 349s 673ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.0169 - val_accuracy: 0.9932\n",
      "Epoch 9/15\n",
      "518/518 [==============================] - 349s 674ms/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
      "Epoch 10/15\n",
      "518/518 [==============================] - 321s 620ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 11/15\n",
      "518/518 [==============================] - 290s 560ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0063 - val_accuracy: 0.9976\n",
      "Epoch 12/15\n",
      "518/518 [==============================] - 297s 573ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0368 - val_accuracy: 0.9880\n",
      "Epoch 13/15\n",
      "518/518 [==============================] - 288s 556ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0139 - val_accuracy: 0.9956\n",
      "Epoch 14/15\n",
      "518/518 [==============================] - 320s 617ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0075 - val_accuracy: 0.9976\n",
      "Epoch 15/15\n",
      "518/518 [==============================] - 323s 622ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.0033 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d7a0689d60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set,validation_data=test_set , epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Class: 24 Z\n",
      "Confidence score: 0.9999997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps #Install pillow instead of PIL\n",
    "#import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "#model = load_model('keras_Model.h5', compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(r\"C:\\Users\\Aditya Babaso Patil\\Desktop\\label.txt\", 'r').readlines()\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224,224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open(r\"C:\\Users\\Aditya Babaso Patil\\PycharmProjects\\pythonProject\\Te\\Image_1673716803.549782.jpg\").convert('RGB')\n",
    "\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.LANCZOS)\n",
    "\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 255)\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = cnn.predict(data)\n",
    "index = np.argmax(prediction)\n",
    "class_name = class_names[index]\n",
    "confidence_score = prediction[0][index]\n",
    "\n",
    "print('Class:', class_name, end='')\n",
    "print('Confidence score:', confidence_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import numpy as np\\nfrom keras.preprocessing import image\\ntest_image = image.load_img('TrainingSet/Test/Image_1673535415.1560686.jpg', target_size = (300,300))\\ntest_image = image.img_to_array(test_image)\\ntest_image = np.expand_dims(test_image, axis = 0)\\nresult = cnn.predict(test_image)\\ntraining_set.class_indices\\n\\nif result[0][0] == 1:\\n  prediction = 'dog'\\nelse:\\n  prediction = 'cat' \""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('TrainingSet/Test/Image_1673535415.1560686.jpg', target_size = (300,300))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat' ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ED9KB3I54c1i",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprediction\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"best_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ADITYA~1\\AppData\\Local\\Temp\\tmpmkdzw0d9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ADITYA~1\\AppData\\Local\\Temp\\tmpmkdzw0d9\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8325948"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = tf.keras.models.load_model('best_model2.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_best_model2.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
